import cloudscraper
import json
import time
import re
import pandas as pd
import os
from datetime import datetime
from typing import List, Dict, Optional, Tuple
from smolagents.tools import Tool

class TrendyolCommentScraper(Tool):
    """A tool for scraping product comments/reviews from Trendyol."""
    
    name = "trendyol_comment_scraper"
    description = "Scrapes customer reviews from a Trendyol product page URL and exports them to Excel."
    inputs = {
        "url": {
            "type": "string",
            "description": "The Trendyol product page URL to scrape reviews from",
            "nullable": True
        }
    }
    output_type = "string"
    
    def __init__(self):
        super().__init__()
        # TrendyolBaseTool sÄ±nÄ±fÄ±nÄ±n fonksiyonlarÄ±nÄ± kullanmak iÃ§in
        # tools modÃ¼lÃ¼nden bu sÄ±nÄ±fÄ± lazy import ile alÄ±yoruz
        from tools import TrendyolBaseTool
        self.base_tool = TrendyolBaseTool()
    
    # Function to extract content ID from the URL
    def extract_content_id(self, url: str) -> Optional[str]:
        match = re.search(r'p-(\d+)', url)
        if match:
            return match.group(1)
        else:
            return None
    
    # Function to fetch product reviews
    def fetch_reviews(self, content_id: str, max_pages: int = 300):
        # Cloudscraper oluÅŸtur
        scraper = cloudscraper.create_scraper()
        
        # Header'lar
        headers = {
            "user-agent": "Mozilla/5.0",
            "accept": "application/json, text/plain, */*",
            "referer": f"https://www.trendyol.com/",
            "origin": "https://www.trendyol.com"
        }
        
        all_reviews = []
        error_count = 0  # Hata sayÄ±sÄ±nÄ± takip etmek iÃ§in

        for page in range(max_pages):
            try:
                params = {
                    "contentId": content_id,
                    "pageSize": 50,
                    "page": page,
                    "order": "DESC",
                    "orderBy": "LastModifiedDate",
                    "channelId": 1
                }

                response = scraper.get(
                    "https://apigw.trendyol.com/discovery-web-websfxsocialreviewrating-santral/product-reviews-detailed",
                    headers=headers,
                    params=params
                )

                if response.status_code == 200:
                    data = response.json()
                    content = data.get("result", {}).get("productReviews", {}).get("content", [])
                    if not content:
                        print(f"Page {page}: No more reviews.")
                        break

                    all_reviews.extend(content)
                    print(f"Page {page}: Collected {len(content)} reviews. Total: {len(all_reviews)}")
                    time.sleep(0.3)
                else:
                    print(f"Page {page}: Error {response.status_code}")
                    error_count += 1
                    if error_count >= 3:  # 3 ardÄ±ÅŸÄ±k hata sonrasÄ± durdur
                        print("Ã‡ok fazla hata, iÅŸlem durduruluyor.")
                        break
                    continue
            except Exception as e:
                print(f"Page {page}: Exception occurred: {str(e)}")
                error_count += 1
                if error_count >= 3:  # 3 ardÄ±ÅŸÄ±k hata sonrasÄ± durdur
                    print("Ã‡ok fazla hata, iÅŸlem durduruluyor.")
                    break
                continue

        print(f"Toplam {len(all_reviews)} yorum toplandÄ±.")
        return all_reviews
    
    def reviews_to_excel(self, reviews: List[Dict], url: str, content_id: str) -> Tuple[str, str]:
        if not reviews:
            return "ÃœrÃ¼n iÃ§in yorum bulunamadÄ±.", None
        
        print(f"Excel dosyasÄ± oluÅŸturuluyor ({len(reviews)} yorum)...")
            
        try:
            # Create a dataframe from the reviews
            df_data = []
            for review in reviews:
                try:
                    # Temel yorum bilgileri
                    row = {
                        'Yorum ID': review.get('id', ''),
                        'BaÅŸlÄ±k': review.get('commentTitle', ''),
                        'Yorum': review.get('comment', ''),
                        'Puan': review.get('rate', 0),
                        'Tarih': review.get('lastModifiedDate', ''),
                        'KullanÄ±cÄ±': review.get('userFullName', ''),
                        'GÃ¼venilir': review.get('trusted', False),
                        'BeÄŸeni SayÄ±sÄ±': review.get('reviewLikeCount', 0),
                    }
                    
                    # SatÄ±cÄ± bilgisi
                    if 'sellerName' in review:
                        row['SatÄ±cÄ±'] = review.get('sellerName', '')
                    
                    # Elite veya Influencer kullanÄ±cÄ± mÄ±?
                    row['Elite KullanÄ±cÄ±'] = review.get('isElite', False)
                    row['Influencer KullanÄ±cÄ±'] = review.get('isInfluencer', False)
                    
                    # Medya dosyalarÄ± var mÄ±?
                    if 'mediaFiles' in review and review['mediaFiles']:
                        try:
                            media_urls = [media.get('url', '') for media in review['mediaFiles'] if media.get('url')]
                            row['Medya URL'] = '; '.join(media_urls)
                            row['Medya SayÄ±sÄ±'] = len(media_urls)
                        except (AttributeError, TypeError) as e:
                            print(f"Medya dosyalarÄ± iÅŸlenirken hata: {str(e)}")
                            row['Medya URL'] = ''
                            row['Medya SayÄ±sÄ±'] = 0
                        
                    # ÃœrÃ¼n Ã¶zellikleri
                    if 'productAttributes' in review and review['productAttributes']:
                        try:
                            attr_text = []
                            if isinstance(review['productAttributes'], dict):
                                for key, value in review['productAttributes'].items():
                                    attr_text.append(f"{key}: {value}")
                            row['ÃœrÃ¼n Ã–zellikleri'] = '; '.join(attr_text)
                        except (AttributeError, TypeError) as e:
                            print(f"ÃœrÃ¼n Ã¶zellikleri iÅŸlenirken hata: {str(e)}")
                            row['ÃœrÃ¼n Ã–zellikleri'] = ''
                        
                    df_data.append(row)
                except Exception as e:
                    print(f"Yorum iÅŸlenirken hata: {str(e)}. Bu yorum atlanÄ±yor.")
                    continue
                
            df = pd.DataFrame(df_data)
            
            # Format dates if available
            if 'Tarih' in df.columns:
                try:
                    # Ã–nce TÃ¼rkÃ§e tarih formatlarÄ±nÄ± kontrol et (Ã¶rn: "19 Åubat 2025")
                    turkish_months = {
                        'Ocak': '01', 'Åubat': '02', 'Mart': '03', 'Nisan': '04', 
                        'MayÄ±s': '05', 'Haziran': '06', 'Temmuz': '07', 'AÄŸustos': '08',
                        'EylÃ¼l': '09', 'Ekim': '10', 'KasÄ±m': '11', 'AralÄ±k': '12'
                    }
                    
                    # Tarih sÃ¼tununu iÅŸle
                    parsed_dates = []
                    for date_str in df['Tarih']:
                        try:
                            # EÄŸer bu bir TÃ¼rkÃ§e tarih formatÄ± ise (19 Åubat 2025)
                            if isinstance(date_str, str) and any(month in date_str for month in turkish_months):
                                for month_name, month_num in turkish_months.items():
                                    if month_name in date_str:
                                        # "19 Åubat 2025" -> "19-02-2025"
                                        date_str = date_str.replace(month_name, month_num)
                                        day, month, year = date_str.split()
                                        parsed_date = f"{year}-{month}-{day.zfill(2)}"
                                        parsed_dates.append(parsed_date)
                                        break
                            else:
                                # Timestamp olabilir
                                if pd.notna(date_str) and not isinstance(date_str, str):
                                    try:
                                        # Unix timestamp'i milisaniye olarak kabul et
                                        dt = pd.to_datetime(date_str, unit='ms')
                                        parsed_dates.append(dt.strftime('%Y-%m-%d %H:%M'))
                                    except:
                                        parsed_dates.append(None)
                                else:
                                    parsed_dates.append(None)
                        except:
                            parsed_dates.append(None)
                    
                    # DÃ¶nÃ¼ÅŸtÃ¼rÃ¼lmÃ¼ÅŸ tarihleri ata
                    df['Tarih'] = parsed_dates
                    
                    # Herhangi bir eksik deÄŸer iÃ§in yeniden deneme yap
                    mask = df['Tarih'].isna()
                    if mask.any():
                        # Tarih formatÄ±nÄ± belirterek dÃ¶nÃ¼ÅŸtÃ¼rmeyi dene
                        df.loc[mask, 'Tarih'] = pd.to_datetime(
                            df.loc[mask, 'Tarih'], 
                            format='%Y-%m-%d', 
                            errors='coerce'
                        ).dt.strftime('%Y-%m-%d')
                except Exception as e:
                    print(f"Tarih dÃ¶nÃ¼ÅŸÃ¼mÃ¼nde hata: {str(e)}")
            
            # Excel dosyasÄ±nÄ± geÃ§ici dizine kaydet
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"yorumlar_{content_id}_{timestamp}.xlsx"
            filepath = os.path.join(self.base_tool._temp_dir, filename)
            
            # Save to Excel
            df.to_excel(filepath, index=False, engine='openpyxl')
            
            # GeÃ§ici dosya olarak kaydet (30 dakika sonra otomatik silinecek)
            self.base_tool.register_temp_file(filepath, ttl_minutes=30)
            
            # JSON yedek olarak da kaydet
            json_filename = f"yorumlar_{content_id}_{timestamp}.json"
            json_filepath = os.path.join(self.base_tool._temp_dir, json_filename)
            with open(json_filepath, 'w', encoding='utf-8') as f:
                json.dump(reviews, f, ensure_ascii=False, indent=4)
            self.base_tool.register_temp_file(json_filepath, ttl_minutes=30)
            
            return filename, self.base_tool.get_file_url(filename)
            
        except Exception as e:
            print(f"Excel dosyasÄ± oluÅŸturulurken hata: {str(e)}")
            return f"Excel dosyasÄ± oluÅŸturulurken hata: {str(e)}", None
    
    def forward(self, url: Optional[str] = None) -> str:
        """
        Scrape customer reviews from a Trendyol product page URL and export them to Excel.
        
        Args:
            url: The Trendyol product page URL to scrape reviews from
        """
        if not url or url.strip() == "":
            return "LÃ¼tfen Trendyol Ã¼rÃ¼n URLsini girin."
        
        print(f"Trendyol yorum taramasÄ± baÅŸlatÄ±lÄ±yor: {url}")
        
        # Extract content ID from URL
        content_id = self.extract_content_id(url)
        if not content_id:
            return "URLden Ã¼rÃ¼n ID Ã§Ä±karÄ±lamadÄ±. GeÃ§erli bir Trendyol Ã¼rÃ¼n URL'si girin."
        
        try:
            # Fetch reviews
            start_time = time.time()
            reviews = self.fetch_reviews(content_id)
            end_time = time.time()
            
            if not reviews:
                return f"Bu Ã¼rÃ¼n iÃ§in yorum bulunamadÄ±: {url}"
                
            # Convert to Excel and get the filename
            excel_filename, excel_path = self.reviews_to_excel(reviews, url, content_id)
            
            if not excel_path:
                return excel_filename  # Hata mesajÄ± dÃ¶nmÃ¼ÅŸ olacak
            
            # Ä°statistikler
            ratings = [review.get('rate', 0) for review in reviews if 'rate' in review]
            rating_counts = {i: ratings.count(i) for i in range(1, 6)}
            
            # KullanÄ±cÄ± bilgileri
            elite_users = len([r for r in reviews if r.get('isElite', False)])
            influencer_users = len([r for r in reviews if r.get('isInfluencer', False)])
            trusted_users = len([r for r in reviews if r.get('trusted', False)])
            
            # Yorum uzunluÄŸu ve iÃ§eriÄŸi analizi
            comment_lengths = [len(review.get('comment', '')) for review in reviews if 'comment' in review]
            avg_comment_length = sum(comment_lengths) / len(comment_lengths) if comment_lengths else 0
            
            # SonuÃ§ mesajÄ± oluÅŸtur
            result = f"âœ… Yorum taramasÄ± tamamlandÄ±!\n\n"
            result += f"**Toplam {len(reviews)} yorum toplandÄ± ve Excel dosyasÄ±na kaydedildi.**\n\n"
            result += f"**Tarama sÃ¼resi**: {end_time - start_time:.2f} saniye\n\n"
            
            # Ä°statistikler
            result += "ğŸ“Š **DeÄŸerlendirme Ä°statistikleri**\n\n"
            
            # YÄ±ldÄ±z daÄŸÄ±lÄ±mÄ±
            result += "**YÄ±ldÄ±z DaÄŸÄ±lÄ±mÄ±**:\n"
            total_ratings = sum(rating_counts.values())
            for star in range(5, 0, -1):
                count = rating_counts.get(star, 0)
                percentage = (count / total_ratings) * 100 if total_ratings > 0 else 0
                result += f"{star} â­: {count} yorum ({percentage:.1f}%)\n"
            
            # Ortalama deÄŸerlendirme puanÄ±
            avg_rating = sum(star * count for star, count in rating_counts.items()) / total_ratings if total_ratings > 0 else 0
            result += f"\n**Ortalama DeÄŸerlendirme**: {avg_rating:.1f} / 5\n"
            
            # KullanÄ±cÄ± bilgileri
            result += f"\n**KullanÄ±cÄ± Ä°statistikleri**:\n"
            result += f"Elite KullanÄ±cÄ±lar: {elite_users} yorum ({elite_users/len(reviews)*100:.1f}%)\n"
            result += f"Influencer KullanÄ±cÄ±lar: {influencer_users} yorum ({influencer_users/len(reviews)*100:.1f}%)\n"
            result += f"GÃ¼venilir KullanÄ±cÄ±lar: {trusted_users} yorum ({trusted_users/len(reviews)*100:.1f}%)\n"
            
            # Yorum uzunluÄŸu
            result += f"\n**Yorum UzunluÄŸu**: Ortalama {avg_comment_length:.0f} karakter\n\n"
            
            result += f"**Dosya AdÄ±**: {excel_filename}\n\n"
            
            # Dosya indirme baÄŸlantÄ±larÄ±
            if os.environ.get('SPACE_ID'):
                # Huggingface Spaces'te Ã§alÄ±ÅŸÄ±yorsa
                space_name = os.environ.get('SPACE_ID')
                result += f"**ğŸ“¥ Ä°ndirme Linkleri**:\n"
                result += f"- [Excel Ä°ndir](/{space_name}/file={excel_path})\n\n"
                result += "**NOT**: Dosyalar 30 dakika sonra otomatik olarak silinecektir. LÃ¼tfen bu sÃ¼re iÃ§inde indirin."
            else:
                # Yerel geliÅŸtirmede
                result += f"**ğŸ“¥ Ä°ndirme Linkleri**:\n"
                result += f"- [Excel Ä°ndir]({excel_path})\n\n"
                result += "**NOT**: Dosyalar 30 dakika sonra otomatik olarak silinecektir."
                
            return result
            
        except Exception as e:
            import traceback
            error_trace = traceback.format_exc()
            print(f"Hata ayrÄ±ntÄ±larÄ±: {error_trace}")
            return f"Yorumlar Ã§ekilirken bir hata oluÅŸtu: {str(e)}"
